<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Git同时配置Gitee和GitHub</title>
      <link href="/2023/07/22/Git%E5%90%8C%E6%97%B6%E9%85%8D%E7%BD%AEGitee%E5%92%8CGitHub/"/>
      <url>/2023/07/22/Git%E5%90%8C%E6%97%B6%E9%85%8D%E7%BD%AEGitee%E5%92%8CGitHub/</url>
      
        <content type="html"><![CDATA[<h1 id="Git同时配置Gitee和GitHub"><a href="#Git同时配置Gitee和GitHub" class="headerlink" title="Git同时配置Gitee和GitHub"></a>Git同时配置Gitee和GitHub</h1><p>注意，以下基本都在 <code>~/.ssh</code> 目录下以及在这个目录下打开的Git Bash窗口中操作，因此打开 <code>~/.ssh</code> 目录及Git Bash窗口后，暂时不要关闭！</p><h2 id="配置Git用户名和邮箱"><a href="#配置Git用户名和邮箱" class="headerlink" title="配置Git用户名和邮箱"></a>配置Git用户名和邮箱</h2><p>首先，为Git设置用户名和邮箱。（若已设置过，则无需设置）</p><pre><code class="shell">git config --global user.name 用户名git config --global user.email 邮箱</code></pre><h2 id="生成SSH-keys"><a href="#生成SSH-keys" class="headerlink" title="生成SSH keys"></a>生成SSH keys</h2><p>许多Git托管网站（如Gitee和GitHub）都使用SSH协议进行认证，因此为了向Gitee和GitHub提供SSH公钥，必须事先为其生成一份SSH密钥对。这个过程在所有操作系统上都是相似的：</p><ol><li><p>进入存放密钥对的文件夹，SSH密钥对存放在 <code>~/.ssh</code> 目录下。在Windows系统下，安装键盘的 <code>Windows</code> 键和 <code>R</code> 键输入 <code>.ssh</code> 回车即可打开</p><p><img src="/2023/07/22/Git%E5%90%8C%E6%97%B6%E9%85%8D%E7%BD%AEGitee%E5%92%8CGitHub/1.jpg" alt="1"></p></li><li><p>生成SSH keys</p><p>在<code>~/.ssh</code> 目录下进入Git Bash，输入下列命令然后一直回车即可：</p><pre><code class="shell">ssh-keygen -t rsa -f id_rsa.gitee -C &quot;gitee&quot;ssh-keygen -t rsa -f id_rsa.github -C &quot;github&quot;</code></pre><p>参数含义：</p><ul><li>-t：指定密钥类型，默认是 rsa ，可以省略</li><li>rsa：指使用RSA算法</li><li>-f：指定存储密钥的文件名</li><li>-C：设置注释文字</li></ul><p>若生成成功，则出现</p><p><img src="/2023/07/22/Git%E5%90%8C%E6%97%B6%E9%85%8D%E7%BD%AEGitee%E5%92%8CGitHub/2.jpg" alt="2"></p><p>同时，在刚才的 <code>.ssh</code> 文件夹下，将会生成4个新文件：</p><p><img src="/2023/07/22/Git%E5%90%8C%E6%97%B6%E9%85%8D%E7%BD%AEGitee%E5%92%8CGitHub/3.jpg" alt="3"></p><p>其中：</p><ul><li>id_rsa.xx：私钥</li><li>id_rsa_xx.xx.pub：私钥对应的公钥</li></ul></li></ol><h2 id="添加私钥到ssh-agent中"><a href="#添加私钥到ssh-agent中" class="headerlink" title="添加私钥到ssh-agent中"></a>添加私钥到ssh-agent中</h2><p>Git默认读取的文件文件名为id_rsa，因此我们需要将生成的密钥添加到ssh-agent中。在刚才打开的Git Bash窗口中输入：</p><pre><code class="shell">ssh-agent bashssh-add ~/.ssh/id_rsa.giteessh-add ~/.ssh/id_rsa.github</code></pre><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>在 <code>~/.ssh</code> 目录下打开 <code>config</code> 文件，若没有则新建一个名为 <code>config</code> 的文件（<strong>注意，这个文件不带扩展名，全面就叫做config</strong>），然后添加以下内容：</p><blockquote><p>#Gitee<br>Host gitee.com<br>HostName gitee.com<br>PreferredAuthentications publickey<br>User git<br>IdentityFile ~&#x2F;.ssh&#x2F;id_rsa.gitee</p><p>#GitHub<br>Host github.com<br>HostName github.com<br>PreferredAuthentications publickey<br>User git<br>IdentityFile ~&#x2F;.ssh&#x2F;id_rsa.github</p></blockquote><h2 id="添加公钥到托管网站"><a href="#添加公钥到托管网站" class="headerlink" title="添加公钥到托管网站"></a>添加公钥到托管网站</h2><ol><li><p>Gitee添加公钥</p><p>登录Gitee，进入 <code>设置</code> ，点击 <code>SSH公钥</code> ，输入“标题”以及“公钥”。Gitee对应的公钥存放在 <code>id_rsa.gitee.pub</code> 文件中，打开全部复制即可：</p><p><img src="/2023/07/22/Git%E5%90%8C%E6%97%B6%E9%85%8D%E7%BD%AEGitee%E5%92%8CGitHub/4.jpg" alt="4"></p></li><li><p>GitHub添加公钥</p><p>登录GitHub，进入 <code>Settings</code> ，依次点击 <code>SSH and GPG keys</code> -&gt; <code>New SSH key</code> ，输入“Title”以及“Key”。GitHub对应的公钥存放在 <code>id_rsa.github.pub</code> 文件中，打开全部复制即可：</p><p><img src="/2023/07/22/Git%E5%90%8C%E6%97%B6%E9%85%8D%E7%BD%AEGitee%E5%92%8CGitHub/5.jpg" alt="5"></p></li></ol><h2 id="测试是否添加成功"><a href="#测试是否添加成功" class="headerlink" title="测试是否添加成功"></a>测试是否添加成功</h2><p>依次在Git Bash中输入：</p><pre><code class="shell">ssh -T git@gitee.com # 测试Giteessh -T git@github.com # 测试GitHub</code></pre><p>第一次连接会让输入 <code>yes/no</code> ，输入 <code>yes</code> 即可：</p><p><img src="/2023/07/22/Git%E5%90%8C%E6%97%B6%E9%85%8D%E7%BD%AEGitee%E5%92%8CGitHub/6.jpg" alt="6"></p><p>出现下面即代表添加成功：</p><p><img src="/2023/07/22/Git%E5%90%8C%E6%97%B6%E9%85%8D%E7%BD%AEGitee%E5%92%8CGitHub/7.jpg" alt="7"></p>]]></content>
      
      
      <categories>
          
          <category> 开发工具 </category>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
            <tag> Git技巧 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对使用Git、GitHub时邮箱和用户名的理解</title>
      <link href="/2023/07/13/%E5%AF%B9%E4%BD%BF%E7%94%A8Git%E3%80%81GitHub%E6%97%B6%E9%82%AE%E7%AE%B1%E5%92%8C%E7%94%A8%E6%88%B7%E5%90%8D%E7%9A%84%E7%90%86%E8%A7%A3/"/>
      <url>/2023/07/13/%E5%AF%B9%E4%BD%BF%E7%94%A8Git%E3%80%81GitHub%E6%97%B6%E9%82%AE%E7%AE%B1%E5%92%8C%E7%94%A8%E6%88%B7%E5%90%8D%E7%9A%84%E7%90%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="对使用Git、GitHub时邮箱和用户名的理解"><a href="#对使用Git、GitHub时邮箱和用户名的理解" class="headerlink" title="对使用Git、GitHub时邮箱和用户名的理解"></a>对使用Git、GitHub时邮箱和用户名的理解</h1><p>在使用Git以及GitHub时会多次用到“邮箱”和“用户名”，这里记录一下它们的区别。</p><h2 id="登录GitHub时"><a href="#登录GitHub时" class="headerlink" title="登录GitHub时"></a>登录GitHub时</h2><p><img src="/2023/07/13/%E5%AF%B9%E4%BD%BF%E7%94%A8Git%E3%80%81GitHub%E6%97%B6%E9%82%AE%E7%AE%B1%E5%92%8C%E7%94%A8%E6%88%B7%E5%90%8D%E7%9A%84%E7%90%86%E8%A7%A3/1.jpg" alt="1"></p><p>这里的用户名或邮箱是<strong>用于登录GitHub</strong>这个网站的。</p><h2 id="配置Git时"><a href="#配置Git时" class="headerlink" title="配置Git时"></a>配置Git时</h2><pre><code class="shell">git config --global user.name &quot;用户名&quot;git config --global user.email &quot;邮箱&quot;</code></pre><p>这两条命令是配置 Git 的全局用户名和邮箱，在进行版本控制时用于记录用户身份信息。Git在commit信息中会显示提交人及其邮箱地址，方便追踪提交记录。因此这里的邮箱和用户名是<strong>为了回溯是谁提交的代码</strong>，并不需要一定填写GitHub的用户名和邮箱，甚至是可以随便填写的用户名和邮箱（当然，极其不建议这样做）。</p><p>在使用GitHub时，可能会发现一个bug：虽然提交了commit，但是主页却不显示contributions。这个bug很可能就是在Git配置的邮箱地址与GitHub中的邮箱地址不符合造成的。</p><ul><li>如果本地设定的user.email值与GitHub上的账户的邮件地址相同，GitHub会认定推送代码的操作是账户拥有者自己做的，跟直接登录到GitHub，从网站上修改，是相同的。此时，修改人是一样，就是账户拥有者。</li><li>如果本地设定的user.email值与GitHub不同，也能把代码推送到GitHub（只要密码或者ssh正确），GitHub会记录这次的修改是另一个人做的。</li></ul><h2 id="设置SSH-Key时"><a href="#设置SSH-Key时" class="headerlink" title="设置SSH Key时"></a>设置SSH Key时</h2><p>GitHub通过HTTPS协议（密码）或者SSH验证身份。其中：</p><ul><li>HTTPS协议只认账号。如果使用HTTPS操作远程仓库，则需要使用账号密码来做权限的认证。</li><li>SSH协议只认机器。当使用SSH操作远程仓库的话，需要使用公钥和私钥对来做权限的认证。</li></ul><p>为了方便操作，一般都是使用SSH协议，当使用SSH协议时，需要在本地电脑上生成公钥和私钥对，然后在GitHub上配置公钥。公钥和私钥对使用如下指令生成：</p><pre><code class="shell">ssh-keygen -t rsa -f id_rsa.github -C &quot;XXX&quot;</code></pre><p>其中：</p><ul><li>-t：指定密钥的类型，密钥的类型有RSA和DSA两种</li><li>rsa：指使用RSA算法</li><li>-f：指定存储密钥的文件名</li><li>-C：表示提供<strong>一个用于识别这个密钥的注释，一般填写邮箱地址，但也可以填入其他内容</strong></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li><p>Git配置邮箱和用户名的目的</p><p>作为一个分布式版本控制系统，远程仓库为了跟踪是谁提交的代码，需要提交这提供身份信息：邮箱和用户名。当然，由于这里的用户名和邮箱完全由提交者设置，所以可能会出现提交者随意填写的情况发生。不过，当这种情况发生时，可以通过一些机制查询出真正的提交者。</p></li><li><p>Git配置的邮箱和用户名和GitHub有什么关系</p><ul><li>账号密码和公钥私钥对只做权限的认证，即判断当前用户或机器是否可以向GitHub中的仓库推送代码。但是这两种认证方式不会记录是由谁把代码推送到GitHub中的，所以使用Git在本地配置的邮箱和用户名作为标记用于记录是谁做的推送操作。即：<ul><li>账号密码和公钥私钥对用于认证，即打开GitHub的大门</li><li>Git配置的邮箱和用户名用于记录是谁向GitHub推送的代码，即记录下是谁在GitHub中做的操作</li></ul></li></ul></li><li><p>Git和GitHub可不可以配置不同的邮箱和用户名</p><p>可以，但最好还是配置相同的邮箱和用户名。正如上面所说，只有这样，GitHub中才能正确的记录你的操作。另外：</p><ul><li>如果Git配置的邮箱是GitHub中存在的邮箱，则commits里显示的是这个邮箱对应的账号</li><li>如果Git配置的邮箱是一个在GitHub里不存在的邮箱，则commits里显示的是Git配置的用户名</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 开发工具 </category>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
            <tag> Git技巧 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch中nn.XXX与F.XXX的区别</title>
      <link href="/2023/07/12/PyTorch%E4%B8%ADnn-XXX%E4%B8%8EF-XXX%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/2023/07/12/PyTorch%E4%B8%ADnn-XXX%E4%B8%8EF-XXX%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorch中nn-XXX与F-XXX的区别"><a href="#PyTorch中nn-XXX与F-XXX的区别" class="headerlink" title="PyTorch中nn.XXX与F.XXX的区别"></a>PyTorch中nn.XXX与F.XXX的区别</h1><h2 id="nn-XXX与F-XXX"><a href="#nn-XXX与F-XXX" class="headerlink" title="nn.XXX与F.XXX"></a>nn.XXX与F.XXX</h2><p>PyTorch中torch.nn<strong>（以下简写为nn）</strong>中的模块和torch.nn.functional<strong>（以下简写为F）</strong>中的模块都提供了常用的神经网络操作，包括激活函数、损失函数、池化操作等。它们的主要区别如下：</p><ul><li>nn中的模块是以类形式存在的；F中的模块是以函数形式存在的</li><li>nn中的模块是nn.Module的子类，包含可学习参数、可导，在反向传播中可以计算梯度，可以在模型中作为子模块使用；F中的模块是纯函数，没有与之相关联的可学习参数，虽然也可以用于反向传播，但是其梯度需要手动计算</li><li>nn中的模块需要实例化后，将张量作为实例的调用参数；F中的模块直接传递张量作为参数</li><li>nn中的模块可以管理和访问模块的内部参数和状态；F中的函数是纯函数，没有与之相关联的参数或状态，因此无法直接管理和访问函数的内部状态</li></ul><h2 id="nn-Relu与F-relu"><a href="#nn-Relu与F-relu" class="headerlink" title="nn.Relu与F.relu()"></a>nn.Relu与F.relu()</h2><p>以激活函数ReLu为例，在使用激活函数时，有以下两种方式可以使用：</p><pre><code class="python"># 方法一nn.ReLU()# 方法二F.relu(input)</code></pre><p>这两种方法都是使用ReLu激活，但使用的场景不一样。</p><ul><li><p>nn.ReLU是一个类，必须实例化后才能使用，一般在<strong>定义网络层</strong>的时候使用</p><pre><code class="python"># nn.ReLU的常用方法nn.Sequential(            nn.Conv2d(in_channels, out_channels),            nn.ReLU(inplace=True)        )</code></pre></li><li><p>F.relu()是函数调用，一般使用在<strong>foreward()函数</strong>中</p></li><li><p>nn.ReLU只能处理Variable类型的张量；而F.relu()可以处理Tensor和Variable类型的张量</p></li><li><p>nn.ReLU需要额外占用内存用来存储中间结果；而F.relu()则是直接在原张量上进行操作，不需要额外的内存占用</p></li></ul><p>另外：</p><ul><li>当用print()打印输出神经网络时，会输出nn.ReLU()层，而F.relu()是没有输出的</li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> PyTorch技巧 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch搭建神经网络</title>
      <link href="/2023/07/12/PyTorch%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2023/07/12/PyTorch%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorch搭建神经网络"><a href="#PyTorch搭建神经网络" class="headerlink" title="PyTorch搭建神经网络"></a>PyTorch搭建神经网络</h1><ul><li>PyTorch版本：1.12.1</li><li><a href="https://pytorch.org/docs/stable/index.html">PyTorch官方文档</a></li><li><a href="https://pytorch.apachecn.org/#/">PyTorch中文文档</a></li></ul><p>PyTorch中搭建并训练一个神经网络分为以下几步：</p><ol><li>定义神经网络</li><li>定义损失函数以及优化器</li><li>训练：反向传播、梯度下降</li></ol><p>下面以LeNet-5为例，搭建一个卷积神经网络用于手写数字识别。</p><h2 id="1-模型简介——LeNet-5"><a href="#1-模型简介——LeNet-5" class="headerlink" title="1. 模型简介——LeNet-5"></a>1. 模型简介——LeNet-5</h2><p><a href="https://ieeexplore.ieee.org/abstract/document/726791">LeNet-5</a>是一个经典的深度卷积神经网络，由Yann LeCun在1998年提出用于解决手写数字识别问题。该网络是第一个被广泛应用于数字图像识别的神经网络之一，也是深度学习领域的里程碑之一，被认为是卷积神经网络的起源之一。</p><p>如下图所示，LeNet-5的结构是一个7层的卷积神经网络（不含输入层），其中包括2个卷积层、2个下采样层（池化层）、2个全连接层以及输出层。</p><p><img src="/2023/07/12/PyTorch%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.jpg" alt="1"></p><h3 id="1-1-输入层（Input-layer"><a href="#1-1-输入层（Input-layer" class="headerlink" title="1.1 输入层（Input layer)"></a>1.1 输入层（Input layer)</h3><p>输入层接收大小为 32*32 的灰度手写数字图像，像素灰度值范围为0-255。为了加快训练速度以及提高模型准确性，通常会对输入图像的像素值进行归一化。</p><h3 id="1-2卷积层C1（Convolutional-layer-C1）"><a href="#1-2卷积层C1（Convolutional-layer-C1）" class="headerlink" title="1.2卷积层C1（Convolutional layer C1）"></a>1.2卷积层C1（Convolutional layer C1）</h3><p>卷积层C1含有6个卷积核，每个卷积核的大小为 5*5 ，步长为1，填充为0。卷积层C1产生6个大小为 28*28 的特征图。</p><h3 id="1-3-下采样层S2（Subsampling-layer-S2）"><a href="#1-3-下采样层S2（Subsampling-layer-S2）" class="headerlink" title="1.3 下采样层S2（Subsampling layer S2）"></a>1.3 下采样层S2（Subsampling layer S2）</h3><p>采样层S2采用最大池化（max-pooling）操作，这可以减少特征图的大小从而提高计算效率，并且池化操作对于轻微的位置变化可以保持一定的不变性。池化层每个窗口的大小为 2*2 ，步长为2。池化层S2产生6个大小为 14*14 的特征图。</p><h3 id="1-4-卷积层C3（Convolutional-layer-C3）"><a href="#1-4-卷积层C3（Convolutional-layer-C3）" class="headerlink" title="1.4 卷积层C3（Convolutional layer C3）"></a>1.4 卷积层C3（Convolutional layer C3）</h3><p>卷积层C3包括16个卷积核，每个卷积核的大小为 5*5 ，步长为1，填充为0。卷积层C1产生16个大小为 10*10的特征图。</p><h3 id="1-5-下采样层S4（Subsampling-layer-S4）"><a href="#1-5-下采样层S4（Subsampling-layer-S4）" class="headerlink" title="1.5 下采样层S4（Subsampling layer S4）"></a>1.5 下采样层S4（Subsampling layer S4）</h3><p>下采样层S4采用最大池化操作，每个窗口的大小为 2*2 ，步长为2。池化层S4产生16个大小为 5*5 的特征图。</p><h3 id="1-6-全连接层C5（Fully-connected-layer-C5）"><a href="#1-6-全连接层C5（Fully-connected-layer-C5）" class="headerlink" title="1.6 全连接层C5（Fully connected layer C5）"></a>1.6 全连接层C5（Fully connected layer C5）</h3><p>C5将16个大小为 5*5 的特征图拉成一个长度为400的向量，并通过一个包括120个神经元的全连接层。120是由LeNet-5的设计者根据实验得到的最佳值。</p><h3 id="1-7-全连接层F6（Fully-connected-layer-F6）"><a href="#1-7-全连接层F6（Fully-connected-layer-F6）" class="headerlink" title="1.7 全连接层F6（Fully connected layer F6）"></a>1.7 全连接层F6（Fully connected layer F6）</h3><p>全连接层F6将120个神经元连接到84个神经元。</p><h3 id="1-8-输出层（Output-layer）"><a href="#1-8-输出层（Output-layer）" class="headerlink" title="1.8 输出层（Output layer）"></a>1.8 输出层（Output layer）</h3><p>输出层由10个神经元组成，每个神经元对应0-9的激活值（激活值越大，是该数字的可能性越大）。模型训练时，使用交叉熵损失函数计算输出层与样本真实标签之间的误差，然后通过反向传播算法更新模型的参数（包括卷积核和全连接层）直至模型达到指定效果或者达到指定迭代次数。</p><p><strong>在实际应用中，通常会对LeNet-5进行一些改进，例如增加网络深度、增加卷积核数量、添加正则化等方法，以进一步提高模型的准确性和泛化能力。</strong></p><h2 id="2-数据集简介——MNIST"><a href="#2-数据集简介——MNIST" class="headerlink" title="2. 数据集简介——MNIST"></a>2. 数据集简介——MNIST</h2><p><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>是一个手写体数字的图片数据集，包含60,000个训练图像和10,000个测试图像，由美国国家标准与技术研究所（National Institute of Standards and Technology (NIST)）发起整理，一共统计了来自250个不同的人手写数字图片，其中50%是高中生，50%来自人口普查局的工作人员。<strong>数据集中的图像都是灰度图像，大小为 28*28 像素，每个像素点的值为 0 到 255 之间的灰度值</strong>。</p><p>使用torchvision中的datasets可自动下载该数据集：</p><pre><code class="python">train_dataset = torchvision.datasets.MNIST(root=&quot;data/&quot;, train=True, transform=transforms.ToTensor(), download=True)test_dataset = torchvision.datasets.MNIST(root=&quot;data/&quot;, train=False, transform=transforms.ToTensor(), download=True)</code></pre><p>其中：</p><ul><li><p>root表示将数据集存放在当前目录下的’data’文件夹中。</p></li><li><p>train&#x3D;True表示导入的是训练数据；train&#x3D;False表示导入的是测试数据。</p></li><li><p>transform表示对每个数据进行的变化，这里是将其变为Tensor，Tensor是PyTorch中存储数据的主要格式。</p></li><li><p>download表示是否将数据下载到本地。</p></li></ul><h2 id="3-定义神经网络"><a href="#3-定义神经网络" class="headerlink" title="3. 定义神经网络"></a>3. 定义神经网络</h2><p>PyTorch中主要有以下两种方式定义神经网络</p><h3 id="3-1-使用前馈神经网络方式"><a href="#3-1-使用前馈神经网络方式" class="headerlink" title="3.1 使用前馈神经网络方式"></a>3.1 使用前馈神经网络方式</h3><p>这种方法需要<strong>继承torch.nn.Module</strong>并且<strong>实现__init__()和forward()这两个方法</strong>。其中__init__()可以用于做一些初始化工作，比如定义输入数据、隐藏层、激活函数等；forward()是实现前向传播的核心函数，用于定义神经网络的结构和参数，在前向传播的过程中，输入的数据将按照该函数定义的神经网络结构进行计算并得到最终的输出。</p><pre><code class="python">import torch.nn.functional as Ffrom torch import nnclass my_CNN(nn.Module):    def __init__(self, in_channels):        super(my_CNN, self).__init__()        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5, stride=1)  # 定义卷积核        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 定义最大池化层        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)  # 定义全连接层        self.fc2 = nn.Linear(in_features=120, out_features=84)        self.fc3 = nn.Linear(in_features=84, out_features=10)    def forward(self, x):        x1 = self.conv1(x)  # 卷积层C1        x2 = F.relu(x1)  # 激活函数        x3 = self.pool1(x2)  # 下采样层S2        x4 = self.conv2(x3)  # 卷积层C3        x5 = F.relu(x4)        x6 = self.pool2(x5)  # 下采样层S4        x7 = x.reshape(x6.shape[0], -1)  # 二维变成一维，以输入到全连接层        x8 = self.fc1(x7)  # 全连接层C5        x9 = F.relu(x8)        x10 = self.fc2(x9)  # 全连接层F6        x11 = F.relu(x10)        x12 = self.fc3(x11)  # 输出层        return x12</code></pre><p>代码解释</p><ul><li><p>__init__()：</p><p>定义了用到的卷积核、池化层以及全连接层，其中：</p><ul><li>nn.Conv2d，定义二维卷积核。in_channels，输入通道数量；out_channels，输出通道数量；kernel_size，卷积核大小；stride，卷积时的步长。</li><li>nn.MaxPool2d，定义二维最大池化层。kernel_size，池化的窗口大小；stride，池化时的步长。</li><li>nn.Linear，定义全连接层。in_features，输入数据的大小；out_features，输出数据的大小。</li></ul></li><li><p>forward()：</p><p>__init__()函数中仅仅是定义了各个层，但并未将它们连接起来搭建出一个神经网络，forward()函数的作用就是搭建一个神经网络，使得输入的数据沿着指定的结构进行前向传播：</p><ul><li>forward除了self之外，还接收一个参数x作为输入数据。</li><li>x &#x3D; self.conv1(x)：输入的x经过卷积计算后得到x1，对应于卷积层C1。</li><li>x2 &#x3D; F.relu(x1) ：对卷积后的数据进行ReLU激活操作。</li><li>x3 &#x3D; self.pool1(x2) ：对数据进行池化，对应于下采样层S2。</li><li>……</li><li>与上面类似，数据依次经过卷积层C3、下采样层S4、全连接层C5、全连接层F6以及输出层，从而使输入x沿着指定的路径得到最终的输出。</li></ul><p><strong>注：</strong></p><ul><li><p>为了更好的展示数据如何沿着神经网络进行前向传播，这里对每一层的输出设置了不同的变量命名，实际应用时，可以将x1~x12都写作x，只要不影响前向传播即可。</p></li><li><p>二维卷积以及池化操作得到的是二维的特则图，但全连接层需要一维的数据，因此需要对数据尺寸进行修改，即：</p><pre><code class="python">x7 = x.reshape(x6.shape[0], -1)</code></pre></li></ul></li></ul><h3 id="3-2-使用序列化方法"><a href="#3-2-使用序列化方法" class="headerlink" title="3.2 使用序列化方法"></a>3.2 使用序列化方法</h3><p>这种方式使用torch.nn.Sequential方式定义模型，将神经网络以序列的方式进行连接，每个层使用前面层计算的输出作为输入，并且在内部会维护层与层之间的权重矩阵和偏置向量。</p><pre><code class="python">from torch import nnin_channels = 1model = nn.Sequential(    nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5, stride=1),    nn.ReLU(),    nn.MaxPool2d(kernel_size=2, stride=2),    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),    nn.ReLU(),    nn.MaxPool2d(kernel_size=2, stride=2),    nn.Flatten(),    nn.Linear(in_features=16 * 4 * 4, out_features=120),    nn.Linear(in_features=120, out_features=84),    nn.Linear(in_features=84, out_features=10))</code></pre><h3 id="3-3总结"><a href="#3-3总结" class="headerlink" title="3.3总结"></a>3.3总结</h3><ol><li>第一种可以更好的根据需要搭建网络结构；</li><li>第二种方式网络以序列的方式搭建网络，不适用于复杂网络；</li><li>对于一些复杂的含有重复层的网络，可将两种方式结合使用。序列化方法定义重复层，然后使用第一种方式根据网络结构进行组装。</li></ol><h2 id="4-定义损失函数以及优化器"><a href="#4-定义损失函数以及优化器" class="headerlink" title="4. 定义损失函数以及优化器"></a>4. 定义损失函数以及优化器</h2><ul><li><p>损失函数</p><p>损失函数用于计算真实值和预测值之间的差异。在<a href="https://pytorch.org/docs/stable/nn.html#loss-functions">PyTorch官方文档</a>中，给出了可用的损失函数列表。</p><p>这里，我们使用交叉熵损失函数<strong>torch.nn.CrossEntropyLoss()<strong>。</strong>该损失函数内部自动加上了Softmax</strong>，用于解决多分类问题，也可用于解决二分类问题。</p></li><li><p>优化器</p><p>优化器根据损失函数求出的损失，对神经网络的参数进行更新。在<a href="https://pytorch.org/docs/stable/optim.html">PyTorch官方文档</a>中，给出了可用的优化器。</p><p>这里，我们使用**torch.optim.Adam()**作为我们的优化器。</p></li></ul><pre><code class="python">from torch import nn, optimcriterion = nn.CrossEntropyLoss()  # 损失函数optimizer = optim.Adam(model.parameters())  # 优化器</code></pre><p>其中：</p><ul><li>model.parameters()是待优化的参数。</li></ul><h2 id="5-训练模型"><a href="#5-训练模型" class="headerlink" title="5.训练模型"></a>5.训练模型</h2><p>模型的训练主要包括3部分：</p><ul><li>前向传播</li><li>反向传播</li><li>梯度下降</li></ul><p>简单的说就是取出数据，放到模型里面跑一次得到预测值，计算与真实值之间的损失，然后计算梯度，根据梯度更新一次网络。</p><p>代码实现如下：</p><pre><code class="python">device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)model = my_CNN(1).to(device)  # 加载模型到设备num_epochs = 100for epoch in range(num_epochs):    for batch_idx, (data, label) in enumerate(train_loader):        data = data.to(device=device)  # 加载数据到设备        label = label.to(device=device)        # 前向传播        pre = model(data)        loss = criterion(pre, label)        # 反向传播        optimizer.zero_grad()        loss.backward()        # 梯度下降        optimizer.step()</code></pre><p>其中：</p><ul><li><p>torch.device(‘cuda’ if torch.cuda.is_available() else ‘cpu’)：选择使用GPU或者CPU训练，若电脑有GPU且配置正确，则使用GPU训练，否则使用CPU训练（模型和数据必须都放在GPU或者CPU上）。</p></li><li><p>for epoch in range(num_epochs)：模型训练次数。</p></li><li><p>for batch_idx, (data, label) in enumerate(train_loader)：mini-batch对数据进行小批量训练。</p></li><li><p>前向传播：</p><ul><li>pre &#x3D; model(data)：将数据放入模型中训练。</li><li>loss &#x3D; criterion(pre, label)：通过损失函数得到本次训练的损失。</li></ul></li><li><p>反向传播：</p><ul><li>optimizer.zero_grad()：将梯度归零。训练时通常使用mini-batch方法，<strong>如果不将梯度清零的话，梯度会与上一个batch的梯度相关，因此该函数要写在反向传播和梯度下降之前</strong>。</li><li>loss.backward()：反向传播。计算得到每个参数的梯度。</li></ul></li><li><p>梯度下降</p><p>optimizer.step()：执行一次优化步骤，对参数进行更新。注意：optimizer.step()只负责通过梯度下降对参数进行优化，并不负责产生梯度，梯度是loss.backward()方法产生的。</p></li></ul><h2 id="6-测试模型"><a href="#6-测试模型" class="headerlink" title="6. 测试模型"></a>6. 测试模型</h2><p>模型训练完毕后，可以使用测试集对模型进行测试：</p><pre><code class="python">loss = 0with torch.no_grad():  # 关闭梯度计算    model.eval()  # 评估模式    for batch_idx, (data, label) in enumerate(test_loader):        data = data.to(device=device)        label = label.to(device=device)        pre = model(data)        loss += criterion(pre, label).item()model.train()  # 训练模式loss = loss / len(test_loader.dataset)</code></pre><p>其中：</p><ul><li><p>with torch.no_grad()：关闭梯度计算。在训练模型时，需要计算根据反向传播计算梯度以更新参数，但在对验证集或者测试集进行预测时，并不需要更新参数，因此也就不需要计算梯度。因此，为了避免浪费计算资源，在模型评估时最后关闭梯度计算。</p></li><li><p>model.eval()：将模型切换到评估模式。在神经网络中，出于防止过拟合等目的，一般会加入Dropout和Batch Normalization层，在模型训练阶段，根据输入数据的变化，这些层的参数也会发生变化。<strong>在评估模式下，Dropout层会让所有的网络节点都生效，而Batch Normalization层会停止计算和更新均值和方差，直接使用在训练阶段已经学出的均值和方差。</strong></p></li><li><p>model.train()：将模型切换到训练模式。此时Dropout层使网络中的节点以一定概率失效，Batch Normalization层根据输入的数据更新均值和方差。<strong>在将模型切换到评估模式之后，在下一次训练之前必须再切换到训练模式。</strong></p></li><li><p>注意with torch.no_grad()和model.eval()的区别：</p><p>with torch.no_grad()关闭的是梯度计算，和神经网络整体有关；而model.eval()和梯度没有关系，只和Dropout和Batch Normalization这两层有关系。</p></li></ul><h2 id="7-整体代码"><a href="#7-整体代码" class="headerlink" title="7. 整体代码"></a>7. 整体代码</h2><p>以下是最终的代码（使用前馈神经网络的方式定义神经网络）。由于这里仅仅是为了介绍如何搭建一个模型，另外出于篇幅考虑，对于一些细节方面未做具体改进，主要包括以下几点：</p><ul><li>除了训练集和测试集之外，还可以使用验证集评估模型性能以设置早停</li><li>为了得到更好的模型性能，一般会对数据进行归一化</li></ul><pre><code class="python">import torchimport torch.nn as nnimport torch.nn.functional as Fimport torchvisionfrom torch import optimfrom torch.utils.data import DataLoaderfrom torchvision import transformsclass my_CNN(nn.Module):    def __init__(self, in_channels):        super(my_CNN, self).__init__()        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5, stride=1)  # 定义卷积核        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 定义最大池化层        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)  # 定义全连接层        self.fc2 = nn.Linear(in_features=120, out_features=84)        self.fc3 = nn.Linear(in_features=84, out_features=10)    def forward(self, x):        x = self.conv1(x)  # 卷积层C1        x = F.relu(x)  # 激活函数        x = self.pool1(x)  # 下采样层S2        x = self.conv2(x)  # 卷积层C3        x = F.relu(x)        x = self.pool2(x)  # 下采样层S4        x = x.reshape(x.shape[0], -1)  # 二维变成一维，以输入到全连接层        x = self.fc1(x)  # 全连接层C5        x = F.relu(x)        x = self.fc2(x)  # 全连接层F6        x = F.relu(x)        x = self.fc3(x)  # 输出层        return xdef train(model, criterion, optimizer, train_loader, device, num_epochs=200):    for epoch in range(num_epochs):        for batch_idx, (data, label) in enumerate(train_loader):            data = data.to(device=device)  # 加载数据到设备            label = label.to(device=device)            # 前向传播            pre = model(data)            loss = criterion(pre, label)            # 反向传播            optimizer.zero_grad()            loss.backward()            # 梯度下降            optimizer.step()def test(model, criterion, test_loader, device):    loss = 0    with torch.no_grad():  # 关闭梯度计算        model.eval()  # 评估模式        for batch_idx, (data, label) in enumerate(test_loader):            data = data.to(device=device)            label = label.to(device=device)            pre = model(data)            loss += criterion(pre, label).item()    model.train()  # 训练模式    loss = loss / len(test_loader.dataset)    return lossdef main():    batch_size = 4    num_epochs = 200    train_dataset = torchvision.datasets.MNIST(root=&quot;data/&quot;, train=True, transform=transforms.ToTensor(),                                               download=True)  # 下载数据集    test_dataset = torchvision.datasets.MNIST(root=&quot;data/&quot;, train=False, transform=transforms.ToTensor(), download=True)    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,                              shuffle=True)  # 将数据集(Dataset)自动分成一个个的Batch,以用于批处理    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)    device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)  # 选择加载数据的设备，GPU或者CPU    model = my_CNN(1).to(device)  # 模型和数据应加载到同一种设备上    criterion = nn.CrossEntropyLoss()  # 损失函数    optimizer = optim.Adam(model.parameters())  # 优化器    train(model, criterion, optimizer, train_loader, device, num_epochs)    print(test(model, criterion, test_loader, device))if __name__ == &#39;__main__&#39;:    main()</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> PyTorch入门 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Qt环境安装</title>
      <link href="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"/>
      <url>/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h1 id="Qt环境安装"><a href="#Qt环境安装" class="headerlink" title="Qt环境安装"></a>Qt环境安装</h1><h2 id="下载Qt"><a href="#下载Qt" class="headerlink" title="下载Qt"></a>下载Qt</h2><h3 id="Qt资源下载地址"><a href="#Qt资源下载地址" class="headerlink" title="Qt资源下载地址"></a>Qt资源下载地址</h3><p> <a href="https://download.qt.io/archive">https://download.qt.io/archive</a></p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/1.png" alt="1"></p><p>其中：</p><ul><li><p>qtcreator文件夹下存放的是不同版本的qtcreator，Qt Creator是一个用于Qt开发的轻量级跨平台集成开发环境</p></li><li><p>qt文件夹下存放的是不同版本的qt，Qt是一个跨平台的C++应用程序开发框架</p></li></ul><p>Qt从5.0版本开始自带Qt Creator，因此，若安装5.0以前版本的Qt需要再单独安装Qt Creator。我安装的是5.12.12，自带Qt Creator，因此不需要再单独安装。</p><h3 id="Qt5-12-12下载地址"><a href="#Qt5-12-12下载地址" class="headerlink" title="Qt5.12.12下载地址"></a>Qt5.12.12下载地址</h3><p><a href="https://download.qt.io/archive/qt/5.12/5.12.12](https://download.qt.io/archive/qt/5.12/5.12.12)">https://download.qt.io/archive/qt/5.12/5.12.12](https://download.qt.io/archive/qt/5.12/5.12.12)</a></p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/2.png" alt="2"></p><p>其中：</p><ul><li>.exe是Windows平台下的安装包</li><li>.dmg是Mac平台下的安装包</li><li>.run是Linux平台下的安装包</li></ul><p>点击对应平台下的安装包下载即可。若网页访问速度慢，可访问国内镜像网站：</p><ul><li><p><a href="https://mirrors.ustc.edu.cn/qtproject/archive">中国科学技术大学Qt镜像</a></p></li><li><p><a href="https://mirrors.sjtug.sjtu.edu.cn/qt/archive">上海交通大学Qt镜像</a></p></li></ul><h2 id="安装Qt"><a href="#安装Qt" class="headerlink" title="安装Qt"></a>安装Qt</h2><p>以Windows平台下安装Qt 5.12.12为例，打开安装包：</p><ol><li><p>填写账号</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/3.png" alt="3"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/4.png" alt="4"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/5.png" alt="5"></p></li><li><p>选择安装路径（不要带中文）</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/6.png" alt="6"></p></li><li><p>选择组件，其中：</p><ul><li><p>MSVC：Microsoft Visual C++ Compiler，微软的VC编译器</p></li><li><p>MinGW：Minimalist GNU for Window，将GCC编译器和GNU Binutils移植到Windows平台下的产物，它是一些头文件和使用 GNU 工具集导入库的集合，允许用户在没有第三方 dll 的情况下生成本地的 Windows 程序</p><p><strong><font color="#0000dd">注：</font></strong></p><p><strong><font color="#0000dd">MSVC 和 MingGW 都是很好用的工具，但兼容并不好，比如某项目使用了 MingGW 编译，那么它所链接的库也必须是 MingGW 编译而成。 一般来说，如果仅在 Windows 平台开发，选择 MSVC，可以使用大量的第三方库；如果有跨平台需求，选择 MingGW。</font></strong></p><p><strong><font color="#0000dd">由于两个版本的Qt配置方式完全不同。因此在网上搜配置方法的时候，要加上MSVC或者MinGW这样的关键字搜索。</font></strong></p></li><li><p>UWP：属于 MSVC 编译器生成的 Qt 库，用于开发通用 Windows 平台的应用程序</p></li><li><p>Android：用于 Android 应用开发的 Qt 库</p></li><li><p>Sources：源码包，添加后可以使用源码调试功能</p></li><li><p>Qt Charts：二维图表模块，用于绘制柱状图、饼图、曲线图等常用二维图表</p></li><li><p>Qt Data Visualization：三维数据图表模块，用于数据的三维显示，如散点的三维空间分布、三维曲面等。</p></li></ul><ul><li>Qt Purchasing：用于处理 Android、iOS 和 macOS 上的应用内购买的跨平台 API</li><li>Qt Virtual Keyboard：Qt Quick 虚拟键盘</li><li>Qt WebEngine：集成了Google Chromium Web，充分利用了整个 Qt 图形堆栈集成，允许原生 Qt 控件与 Web 内容和 OpenGL 着色器的无缝混合和叠加</li><li>Qt Network Authorization：Qt 网络授权是一个附加库，它使 Qt 应用程序能够使用不同的 Web 身份验证系统</li><li>Qt WebGL Streaming Plugin：一个 Qt Platform Abstraction 插件，它通过网络将 Qt Quick &amp; Qt OpenGL 应用程序流式传输到支持 WebGL 的浏览器。</li><li><del>Qt Script (Deprecated)：脚本模块，已弃用</del></li></ul><p>Tools 节点下的工具：</p><ul><li><p>Qt Creator：Qt5.0版本以上集成的轻量级跨平台集成开发环境（5.0以下需要单独安装）</p></li><li><p>CDB Debugger Support：控制台调试器，是 MSVC 在 Qt 的原生调试器，由于MSVC 只有编译器，如果选择它，则需要勾选；如选择 MinGW 则不需要，MinGW 中有 GDB调试器</p></li><li><p>MingGW ：这里的 MingGW 是用来交叉编译的，在一个平台上生成另一个平台上的可执行代码</p></li><li><p>Strawberry Perl：Perl 语言工具</p><p>根据个人需要，我选择了以下组件（若不确定选哪个，可以全选）</p></li></ul><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/7.png" alt="7"></p></li><li><p>许可协议</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/8.png" alt="8"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/9.png" alt="9"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/10.png" alt="10"></p></li><li><p>等待安装完成</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/11.png" alt="11"></p></li><li><p>安装完成</p></li></ol><p>   <img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/12.png" alt="12"></p><h2 id="创建快捷方式"><a href="#创建快捷方式" class="headerlink" title="创建快捷方式"></a>创建快捷方式</h2><p>安装好后的Qt Creator未在桌面创建快捷方式，可以使用以下方式创建：</p><ol><li><p>打开“开始菜单”，找到安装好的“Qt Creator”，然后“右键”-&gt;“更多”-&gt;“打开文件位置”</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/13.jpg" alt="13"></p></li><li><p>在“Qt Creator”上右键，然后”发送到”-&gt;“桌面快捷方式”</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/14.jpg" alt="14"></p></li></ol><h2 id="“Hello-World”之第一个Qt应用"><a href="#“Hello-World”之第一个Qt应用" class="headerlink" title="“Hello World”之第一个Qt应用"></a>“Hello World”之第一个Qt应用</h2><ol><li><p>打开Qt Creator，“文件”-&gt;“新建文件或项目”</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/15.png" alt="15"></p></li><li><p>选择模板，部分选项如下：</p><ul><li>Qt Widgets Application，支持桌面平台的GUI 界面应用程序</li><li>Qt Console Application，控制台应用程序，无 GUI 界面</li><li>Application（Qt Quick），创建可部署的 Qt Quick 2 应用程序。Qt Quick 是 Qt 支持的一套 GUI 开发架构，其界面设计采用 QML 语言，程序架构采用 C++ 语言。利用 Qt Quick 可以设计非常炫的用户界面，一般用于移动设备或嵌入式设备上无边框的应用程序的设计</li></ul><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/16.png" alt="16"></p></li><li><p>工程路径，注意路径及工程名字不能含有空格或中文</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/17.png" alt="17"></p></li><li><p>选择构建系统，其中：</p><ul><li>qmake，为 Qt 量身打造的，使用起来非常方便</li><li>cmake，使用上不如qmake简单直接，但复杂换来的是强大的功能</li><li>Qbs ，号称下一代构建工具</li></ul><p>对简单的Qt工程，采用 qmake；对复杂度超过 qmake 处理能力的，采用 cmake。这里我选择qmake。</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/18.png" alt="18"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/19.png" alt="19"></p></li><li><p>翻译文件，用于国际化，暂时不用设置，默认即可</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/20.png" alt="20"></p></li><li><p>选择构建套件，这里我选择MinGW 64-bit，不同构建套件的区别见上面“安装Qt”中的“选择组件”步骤</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/21.png" alt="21"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/22.png" alt="22"></p></li><li><p>打开 .ui 文件</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/23.png" alt="23"></p></li><li><p>在“Display Widgets”下拖一个“Label”到中间，在其中填入“Hello World”，并在右侧修改宽度</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/24.png" alt="24"></p></li><li><p>点击左下角的“绿色三角形”运行程序</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/25.png" alt="25"></p></li><li><p>程序运行成果，显示GUI界面</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/26.png" alt="26"></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 开发工具 </category>
          
          <category> Qt </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> Qt入门 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>离思五首·其四</title>
      <link href="/2023/07/08/%E7%A6%BB%E6%80%9D%E4%BA%94%E9%A6%96%C2%B7%E5%85%B6%E5%9B%9B/"/>
      <url>/2023/07/08/%E7%A6%BB%E6%80%9D%E4%BA%94%E9%A6%96%C2%B7%E5%85%B6%E5%9B%9B/</url>
      
        <content type="html"><![CDATA[<center>离思五首·其四</center><p align="right">元稹【唐】</p><hr><center>曾经沧海难为水，</center><center>除却巫山不是云。</center><center>取次花丛懒回顾，</center><center>半缘修道半缘君。</center><p>第一次读到这首诗的时候，因为没读懂“曾经”两个字，所以对前两句半知半解，只觉得后两句写得很妙。后来某一天突然醒悟过来，“曾经”是两个词：曾经经过，这才体会到前两句的韵味。特别是最近想起来这首诗，更是咂摸出一番新的滋味。<br>“领略过沧海的波涛汹涌，别处的水就不值得看了；沉醉过巫山云景的梦幻飘渺，别处的云都不能被叫作云景了；即使从万花丛中走过，也懒得看一眼”如果只读到前三句，可能会是一头雾水，这到底想表达什么意思？为什么别处的水不值得看？为什么别处的云不能被叫作云景？为什么不看一眼身边的花？正当疑问之时，最后一句点名原因“一半是因为我在修道，另一半是因为你呀！”<br>个人认为，这首诗除了前两句的比喻极其绝妙之外，整体结构上也是极具深意的，可以说是含蓄美的极致体现。前三句不明说对你的爱慕，只是说沧海、说巫山云雨、说万花丛，直到最后一句点睛之笔才知道这哪是在说什么沧海云雨，这句句都是在说心上人啊！哪怕到了最后点名原因了，还要再说一句“半缘修道”，可是真的有一半原因是修道吗？恐怕未必，或者说“修道”本身也是“缘君”。这种写法， 层层递进，先是三句描写自己心态的句子，然后自然而然的说出自己为何这样，虽然整体上感觉不到太大的感情波动，但却将思恋之情委婉而又淋漓尽致的表现了出来。<br>如果换成现在，或许就是这样吧：<br>今天的晚霞好美，像一条红绸带从天边垂下；晚饭也很香，炸鸡腿外焦里嫩，咬一口嘎吱响。<br>但是我不想去看晚霞也没心思吃饭。<br>为什么？<br>因为最近很忙很累，嗯，更重要的是，好久不见想你了……</p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
          <category> 诗 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 诗 </tag>
            
            <tag> 唐 </tag>
            
            <tag> 元稹 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
