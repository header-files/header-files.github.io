<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>PyTorch搭建神经网络</title>
      <link href="/2023/07/12/PyTorch%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2023/07/12/PyTorch%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorch搭建神经网络"><a href="#PyTorch搭建神经网络" class="headerlink" title="PyTorch搭建神经网络"></a>PyTorch搭建神经网络</h1><ul><li>PyTorch版本：1.12.1</li><li><a href="https://pytorch.org/docs/stable/index.html">PyTorch官方文档</a></li><li><a href="https://pytorch.apachecn.org/#/">PyTorch中文文档</a></li></ul><p>PyTorch中搭建并训练一个神经网络分为以下几步：</p><ol><li>定义神经网络</li><li>定义损失函数以及优化器</li><li>训练：反向传播、梯度下降</li></ol><p>下面以LeNet-5为例，搭建一个卷积神经网络用于手写数字识别。</p><h2 id="1-模型简介——LeNet-5"><a href="#1-模型简介——LeNet-5" class="headerlink" title="1. 模型简介——LeNet-5"></a>1. 模型简介——LeNet-5</h2><p><a href="https://ieeexplore.ieee.org/abstract/document/726791">LeNet-5</a>是一个经典的深度卷积神经网络，由Yann LeCun在1998年提出用于解决手写数字识别问题。该网络是第一个被广泛应用于数字图像识别的神经网络之一，也是深度学习领域的里程碑之一，被认为是卷积神经网络的起源之一。</p><p>如下图所示，LeNet-5的结构是一个7层的卷积神经网络（不含输入层），其中包括2个卷积层、2个下采样层（池化层）、2个全连接层以及输出层。</p><p><img src="/2023/07/12/PyTorch%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.jpg" alt="1"></p><h3 id="1-1-输入层（Input-layer"><a href="#1-1-输入层（Input-layer" class="headerlink" title="1.1 输入层（Input layer)"></a>1.1 输入层（Input layer)</h3><p>输入层接收大小为 32*32 的灰度手写数字图像，像素灰度值范围为0-255。为了加快训练速度以及提高模型准确性，通常会对输入图像的像素值进行归一化。</p><h3 id="1-2卷积层C1（Convolutional-layer-C1）"><a href="#1-2卷积层C1（Convolutional-layer-C1）" class="headerlink" title="1.2卷积层C1（Convolutional layer C1）"></a>1.2卷积层C1（Convolutional layer C1）</h3><p>卷积层C1含有6个卷积核，每个卷积核的大小为 5*5 ，步长为1，填充为0。卷积层C1产生6个大小为 28*28 的特征图。</p><h3 id="1-3-下采样层S2（Subsampling-layer-S2）"><a href="#1-3-下采样层S2（Subsampling-layer-S2）" class="headerlink" title="1.3 下采样层S2（Subsampling layer S2）"></a>1.3 下采样层S2（Subsampling layer S2）</h3><p>采样层S2采用最大池化（max-pooling）操作，这可以减少特征图的大小从而提高计算效率，并且池化操作对于轻微的位置变化可以保持一定的不变性。池化层每个窗口的大小为 2*2 ，步长为2。池化层S2产生6个大小为 14*14 的特征图。</p><h3 id="1-4-卷积层C3（Convolutional-layer-C3）"><a href="#1-4-卷积层C3（Convolutional-layer-C3）" class="headerlink" title="1.4 卷积层C3（Convolutional layer C3）"></a>1.4 卷积层C3（Convolutional layer C3）</h3><p>卷积层C3包括16个卷积核，每个卷积核的大小为 5*5 ，步长为1，填充为0。卷积层C1产生16个大小为 10*10的特征图。</p><h3 id="1-5-下采样层S4（Subsampling-layer-S4）"><a href="#1-5-下采样层S4（Subsampling-layer-S4）" class="headerlink" title="1.5 下采样层S4（Subsampling layer S4）"></a>1.5 下采样层S4（Subsampling layer S4）</h3><p>下采样层S4采用最大池化操作，每个窗口的大小为 2*2 ，步长为2。池化层S4产生16个大小为 5*5 的特征图。</p><h3 id="1-6-全连接层C5（Fully-connected-layer-C5）"><a href="#1-6-全连接层C5（Fully-connected-layer-C5）" class="headerlink" title="1.6 全连接层C5（Fully connected layer C5）"></a>1.6 全连接层C5（Fully connected layer C5）</h3><p>C5将16个大小为 5*5 的特征图拉成一个长度为400的向量，并通过一个包括120个神经元的全连接层。120是由LeNet-5的设计者根据实验得到的最佳值。</p><h3 id="1-7-全连接层F6（Fully-connected-layer-F6）"><a href="#1-7-全连接层F6（Fully-connected-layer-F6）" class="headerlink" title="1.7 全连接层F6（Fully connected layer F6）"></a>1.7 全连接层F6（Fully connected layer F6）</h3><p>全连接层F6将120个神经元连接到84个神经元。</p><h3 id="1-8-输出层（Output-layer）"><a href="#1-8-输出层（Output-layer）" class="headerlink" title="1.8 输出层（Output layer）"></a>1.8 输出层（Output layer）</h3><p>输出层由10个神经元组成，每个神经元对应0-9的激活值（激活值越大，是该数字的可能性越大）。模型训练时，使用交叉熵损失函数计算输出层与样本真实标签之间的误差，然后通过反向传播算法更新模型的参数（包括卷积核和全连接层）直至模型达到指定效果或者达到指定迭代次数。</p><p><strong>在实际应用中，通常会对LeNet-5进行一些改进，例如增加网络深度、增加卷积核数量、添加正则化等方法，以进一步提高模型的准确性和泛化能力。</strong></p><h2 id="2-数据集简介——MNIST"><a href="#2-数据集简介——MNIST" class="headerlink" title="2. 数据集简介——MNIST"></a>2. 数据集简介——MNIST</h2><p><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>是一个手写体数字的图片数据集，包含60,000个训练图像和10,000个测试图像，由美国国家标准与技术研究所（National Institute of Standards and Technology (NIST)）发起整理，一共统计了来自250个不同的人手写数字图片，其中50%是高中生，50%来自人口普查局的工作人员。<strong>数据集中的图像都是灰度图像，大小为 28*28 像素，每个像素点的值为 0 到 255 之间的灰度值</strong>。</p><p>使用torchvision中的datasets可自动下载该数据集：</p><pre><code class="python">train_dataset = torchvision.datasets.MNIST(root=&quot;data/&quot;, train=True, transform=transforms.ToTensor(), download=True)test_dataset = torchvision.datasets.MNIST(root=&quot;data/&quot;, train=False, transform=transforms.ToTensor(), download=True)</code></pre><p>其中：</p><ul><li><p>root表示将数据集存放在当前目录下的’data’文件夹中。</p></li><li><p>train&#x3D;True表示导入的是训练数据；train&#x3D;False表示导入的是测试数据。</p></li><li><p>transform表示对每个数据进行的变化，这里是将其变为Tensor，Tensor是PyTorch中存储数据的主要格式。</p></li><li><p>download表示是否将数据下载到本地。</p></li></ul><h2 id="3-定义神经网络"><a href="#3-定义神经网络" class="headerlink" title="3. 定义神经网络"></a>3. 定义神经网络</h2><p>PyTorch中主要有以下两种方式定义神经网络</p><h3 id="3-1-使用前馈神经网络方式"><a href="#3-1-使用前馈神经网络方式" class="headerlink" title="3.1 使用前馈神经网络方式"></a>3.1 使用前馈神经网络方式</h3><p>这种方法需要<strong>继承torch.nn.Module</strong>并且<strong>实现__init__()和forward()这两个方法</strong>。其中__init__()可以用于做一些初始化工作，比如定义输入数据、隐藏层、激活函数等；forward()是实现前向传播的核心函数，用于定义神经网络的结构和参数，在前向传播的过程中，输入的数据将按照该函数定义的神经网络结构进行计算并得到最终的输出。</p><pre><code class="python">import torch.nn.functional as Ffrom torch import nnclass my_CNN(nn.Module):    def __init__(self, in_channels):        super(my_CNN, self).__init__()        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5, stride=1)  # 定义卷积核        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 定义最大池化层        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)  # 定义全连接层        self.fc2 = nn.Linear(in_features=120, out_features=84)        self.fc3 = nn.Linear(in_features=84, out_features=10)    def forward(self, x):        x1 = self.conv1(x)  # 卷积层C1        x2 = F.relu(x1)  # 激活函数        x3 = self.pool1(x2)  # 下采样层S2        x4 = self.conv2(x3)  # 卷积层C3        x5 = F.relu(x4)        x6 = self.pool2(x5)  # 下采样层S4        x7 = x.reshape(x6.shape[0], -1)  # 二维变成一维，以输入到全连接层        x8 = self.fc1(x7)  # 全连接层C5        x9 = F.relu(x8)        x10 = self.fc2(x9)  # 全连接层F6        x11 = F.relu(x10)        x12 = self.fc3(x11)  # 输出层        return x12</code></pre><p>代码解释</p><ul><li><p>__init__()：</p><p>定义了用到的卷积核、池化层以及全连接层，其中：</p><ul><li>nn.Conv2d，定义二维卷积核。in_channels，输入通道数量；out_channels，输出通道数量；kernel_size，卷积核大小；stride，卷积时的步长。</li><li>nn.MaxPool2d，定义二维最大池化层。kernel_size，池化的窗口大小；stride，池化时的步长。</li><li>nn.Linear，定义全连接层。in_features，输入数据的大小；out_features，输出数据的大小。</li></ul></li><li><p>forward()：</p><p>__init__()函数中仅仅是定义了各个层，但并未将它们连接起来搭建出一个神经网络，forward()函数的作用就是搭建一个神经网络，使得输入的数据沿着指定的结构进行前向传播：</p><ul><li>forward除了self之外，还接收一个参数x作为输入数据。</li><li>x &#x3D; self.conv1(x)：输入的x经过卷积计算后得到x1，对应于卷积层C1。</li><li>x2 &#x3D; F.relu(x1) ：对卷积后的数据进行ReLU激活操作。</li><li>x3 &#x3D; self.pool1(x2) ：对数据进行池化，对应于下采样层S2。</li><li>……</li><li>与上面类似，数据依次经过卷积层C3、下采样层S4、全连接层C5、全连接层F6以及输出层，从而使输入x沿着指定的路径得到最终的输出。</li></ul><p><strong>注：</strong></p><ul><li><p>为了更好的展示数据如何沿着神经网络进行前向传播，这里对每一层的输出设置了不同的变量命名，实际应用时，可以将x1~x12都写作x，只要不影响前向传播即可。</p></li><li><p>二维卷积以及池化操作得到的是二维的特则图，但全连接层需要一维的数据，因此需要对数据尺寸进行修改，即：</p><pre><code class="python">x7 = x.reshape(x6.shape[0], -1)</code></pre></li></ul></li></ul><h3 id="3-2-使用序列化方法"><a href="#3-2-使用序列化方法" class="headerlink" title="3.2 使用序列化方法"></a>3.2 使用序列化方法</h3><p>这种方式使用torch.nn.Sequential方式定义模型，将神经网络以序列的方式进行连接，每个层使用前面层计算的输出作为输入，并且在内部会维护层与层之间的权重矩阵和偏置向量。</p><pre><code class="python">from torch import nnin_channels = 1model = nn.Sequential(    nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5, stride=1),    nn.ReLU(),    nn.MaxPool2d(kernel_size=2, stride=2),    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),    nn.ReLU(),    nn.MaxPool2d(kernel_size=2, stride=2),    nn.Flatten(),    nn.Linear(in_features=16 * 4 * 4, out_features=120),    nn.Linear(in_features=120, out_features=84),    nn.Linear(in_features=84, out_features=10))</code></pre><h3 id="3-3总结"><a href="#3-3总结" class="headerlink" title="3.3总结"></a>3.3总结</h3><ol><li>第一种可以更好的根据需要搭建网络结构；</li><li>第二种方式网络以序列的方式搭建网络，不适用于复杂网络；</li><li>对于一些复杂的含有重复层的网络，可将两种方式结合使用。序列化方法定义重复层，然后使用第一种方式根据网络结构进行组装。</li></ol><h2 id="4-定义损失函数以及优化器"><a href="#4-定义损失函数以及优化器" class="headerlink" title="4. 定义损失函数以及优化器"></a>4. 定义损失函数以及优化器</h2><ul><li><p>损失函数</p><p>损失函数用于计算真实值和预测值之间的差异。在<a href="https://pytorch.org/docs/stable/nn.html#loss-functions">PyTorch官方文档</a>中，给出了可用的损失函数列表。</p><p>这里，我们使用交叉熵损失函数<strong>torch.nn.CrossEntropyLoss()<strong>。</strong>该损失函数内部自动加上了Softmax</strong>，用于解决多分类问题，也可用于解决二分类问题。</p></li><li><p>优化器</p><p>优化器根据损失函数求出的损失，对神经网络的参数进行更新。在<a href="https://pytorch.org/docs/stable/optim.html">PyTorch官方文档</a>中，给出了可用的优化器。</p><p>这里，我们使用**torch.optim.Adam()**作为我们的优化器。</p></li></ul><pre><code class="python">from torch import nn, optimcriterion = nn.CrossEntropyLoss()  # 损失函数optimizer = optim.Adam(model.parameters())  # 优化器</code></pre><p>其中：</p><ul><li>model.parameters()是待优化的参数。</li></ul><h2 id="5-训练模型"><a href="#5-训练模型" class="headerlink" title="5.训练模型"></a>5.训练模型</h2><p>模型的训练主要包括3部分：</p><ul><li>前向传播</li><li>反向传播</li><li>梯度下降</li></ul><p>简单的说就是取出数据，放到模型里面跑一次得到预测值，计算与真实值之间的损失，然后计算梯度，根据梯度更新一次网络。</p><p>代码实现如下：</p><pre><code class="python">device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)model = my_CNN(1).to(device)  # 加载模型到设备num_epochs = 100for epoch in range(num_epochs):    for batch_idx, (data, label) in enumerate(train_loader):        data = data.to(device=device)  # 加载数据到设备        label = label.to(device=device)        # 前向传播        pre = model(data)        loss = criterion(pre, label)        # 反向传播        optimizer.zero_grad()        loss.backward()        # 梯度下降        optimizer.step()</code></pre><p>其中：</p><ul><li><p>torch.device(‘cuda’ if torch.cuda.is_available() else ‘cpu’)：选择使用GPU或者CPU训练，若电脑有GPU且配置正确，则使用GPU训练，否则使用CPU训练（模型和数据必须都放在GPU或者CPU上）。</p></li><li><p>for epoch in range(num_epochs)：模型训练次数。</p></li><li><p>for batch_idx, (data, label) in enumerate(train_loader)：mini-batch对数据进行小批量训练。</p></li><li><p>前向传播：</p><ul><li>pre &#x3D; model(data)：将数据放入模型中训练。</li><li>loss &#x3D; criterion(pre, label)：通过损失函数得到本次训练的损失。</li></ul></li><li><p>反向传播：</p><ul><li>optimizer.zero_grad()：将梯度归零。训练时通常使用mini-batch方法，<strong>如果不将梯度清零的话，梯度会与上一个batch的梯度相关，因此该函数要写在反向传播和梯度下降之前</strong>。</li><li>loss.backward()：反向传播。计算得到每个参数的梯度。</li></ul></li><li><p>梯度下降</p><p>optimizer.step()：执行一次优化步骤，对参数进行更新。注意：optimizer.step()只负责通过梯度下降对参数进行优化，并不负责产生梯度，梯度是loss.backward()方法产生的。</p></li></ul><h2 id="6-测试模型"><a href="#6-测试模型" class="headerlink" title="6. 测试模型"></a>6. 测试模型</h2><p>模型训练完毕后，可以使用测试集对模型进行测试：</p><pre><code class="python">loss = 0with torch.no_grad():  # 关闭梯度计算    model.eval()  # 评估模式    for batch_idx, (data, label) in enumerate(test_loader):        data = data.to(device=device)        label = label.to(device=device)        pre = model(data)        loss += criterion(pre, label).item()model.train()  # 训练模式loss = loss / len(test_loader.dataset)</code></pre><p>其中：</p><ul><li><p>with torch.no_grad()：关闭梯度计算。在训练模型时，需要计算根据反向传播计算梯度以更新参数，但在对验证集或者测试集进行预测时，并不需要更新参数，因此也就不需要计算梯度。因此，为了避免浪费计算资源，在模型评估时最后关闭梯度计算。</p></li><li><p>model.eval()：将模型切换到评估模式。在神经网络中，出于防止过拟合等目的，一般会加入Dropout和Batch Normalization层，在模型训练阶段，根据输入数据的变化，这些层的参数也会发生变化。<strong>在评估模式下，Dropout层会让所有的网络节点都生效，而Batch Normalization层会停止计算和更新均值和方差，直接使用在训练阶段已经学出的均值和方差。</strong></p></li><li><p>model.train()：将模型切换到训练模式。此时Dropout层使网络中的节点以一定概率失效，Batch Normalization层根据输入的数据更新均值和方差。<strong>在将模型切换到评估模式之后，在下一次训练之前必须再切换到训练模式。</strong></p></li><li><p>注意with torch.no_grad()和model.eval()的区别：</p><p>with torch.no_grad()关闭的是梯度计算，和神经网络整体有关；而model.eval()和梯度没有关系，只和Dropout和Batch Normalization这两层有关系。</p></li></ul><h2 id="7-整体代码"><a href="#7-整体代码" class="headerlink" title="7. 整体代码"></a>7. 整体代码</h2><p>以下是最终的代码（使用前馈神经网络的方式定义神经网络）。由于这里仅仅是为了介绍如何搭建一个模型，另外出于篇幅考虑，对于一些细节方面未做具体改进，主要包括以下几点：</p><ul><li>除了训练集和测试集之外，还可以使用验证集评估模型性能以设置早停</li><li>为了得到更好的模型性能，一般会对数据进行归一化</li></ul><pre><code class="python">import torchimport torch.nn as nnimport torch.nn.functional as Fimport torchvisionfrom torch import optimfrom torch.utils.data import DataLoaderfrom torchvision import transformsclass my_CNN(nn.Module):    def __init__(self, in_channels):        super(my_CNN, self).__init__()        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5, stride=1)  # 定义卷积核        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 定义最大池化层        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)  # 定义全连接层        self.fc2 = nn.Linear(in_features=120, out_features=84)        self.fc3 = nn.Linear(in_features=84, out_features=10)    def forward(self, x):        x = self.conv1(x)  # 卷积层C1        x = F.relu(x)  # 激活函数        x = self.pool1(x)  # 下采样层S2        x = self.conv2(x)  # 卷积层C3        x = F.relu(x)        x = self.pool2(x)  # 下采样层S4        x = x.reshape(x.shape[0], -1)  # 二维变成一维，以输入到全连接层        x = self.fc1(x)  # 全连接层C5        x = F.relu(x)        x = self.fc2(x)  # 全连接层F6        x = F.relu(x)        x = self.fc3(x)  # 输出层        return xdef train(model, criterion, optimizer, train_loader, device, num_epochs=200):    for epoch in range(num_epochs):        for batch_idx, (data, label) in enumerate(train_loader):            data = data.to(device=device)  # 加载数据到设备            label = label.to(device=device)            # 前向传播            pre = model(data)            loss = criterion(pre, label)            # 反向传播            optimizer.zero_grad()            loss.backward()            # 梯度下降            optimizer.step()def test(model, criterion, test_loader, device):    loss = 0    with torch.no_grad():  # 关闭梯度计算        model.eval()  # 评估模式        for batch_idx, (data, label) in enumerate(test_loader):            data = data.to(device=device)            label = label.to(device=device)            pre = model(data)            loss += criterion(pre, label).item()    model.train()  # 训练模式    loss = loss / len(test_loader.dataset)    return lossdef main():    batch_size = 4    num_epochs = 200    train_dataset = torchvision.datasets.MNIST(root=&quot;data/&quot;, train=True, transform=transforms.ToTensor(),                                               download=True)  # 下载数据集    test_dataset = torchvision.datasets.MNIST(root=&quot;data/&quot;, train=False, transform=transforms.ToTensor(), download=True)    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,                              shuffle=True)  # 将数据集(Dataset)自动分成一个个的Batch,以用于批处理    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)    device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)  # 选择加载数据的设备，GPU或者CPU    model = my_CNN(1).to(device)  # 模型和数据应加载到同一种设备上    criterion = nn.CrossEntropyLoss()  # 损失函数    optimizer = optim.Adam(model.parameters())  # 优化器    train(model, criterion, optimizer, train_loader, device, num_epochs)    print(test(model, criterion, test_loader, device))if __name__ == &#39;__main__&#39;:    main()</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> PyTorch </tag>
            
            <tag> 入门 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Qt环境安装</title>
      <link href="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"/>
      <url>/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h1 id="Qt环境安装"><a href="#Qt环境安装" class="headerlink" title="Qt环境安装"></a>Qt环境安装</h1><h2 id="下载Qt"><a href="#下载Qt" class="headerlink" title="下载Qt"></a>下载Qt</h2><h3 id="Qt资源下载地址"><a href="#Qt资源下载地址" class="headerlink" title="Qt资源下载地址"></a>Qt资源下载地址</h3><p> <a href="https://download.qt.io/archive">https://download.qt.io/archive</a></p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/1.png" alt="1"></p><p>其中：</p><ul><li><p>qtcreator文件夹下存放的是不同版本的qtcreator，Qt Creator是一个用于Qt开发的轻量级跨平台集成开发环境</p></li><li><p>qt文件夹下存放的是不同版本的qt，Qt是一个跨平台的C++应用程序开发框架</p></li></ul><p>Qt从5.0版本开始自带Qt Creator，因此，若安装5.0以前版本的Qt需要再单独安装Qt Creator。我安装的是5.12.12，自带Qt Creator，因此不需要再单独安装。</p><h3 id="Qt5-12-12下载地址"><a href="#Qt5-12-12下载地址" class="headerlink" title="Qt5.12.12下载地址"></a>Qt5.12.12下载地址</h3><p><a href="https://download.qt.io/archive/qt/5.12/5.12.12](https://download.qt.io/archive/qt/5.12/5.12.12)">https://download.qt.io/archive/qt/5.12/5.12.12](https://download.qt.io/archive/qt/5.12/5.12.12)</a></p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/2.png" alt="2"></p><p>其中：</p><ul><li>.exe是Windows平台下的安装包</li><li>.dmg是Mac平台下的安装包</li><li>.run是Linux平台下的安装包</li></ul><p>点击对应平台下的安装包下载即可。若网页访问速度慢，可访问国内镜像网站：</p><ul><li><p><a href="https://mirrors.ustc.edu.cn/qtproject/archive">中国科学技术大学Qt镜像</a></p></li><li><p><a href="https://mirrors.sjtug.sjtu.edu.cn/qt/archive">上海交通大学Qt镜像</a></p></li></ul><h2 id="安装Qt"><a href="#安装Qt" class="headerlink" title="安装Qt"></a>安装Qt</h2><p>以Windows平台下安装Qt 5.12.12为例，打开安装包：</p><ol><li><p>填写账号</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/3.png" alt="3"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/4.png" alt="4"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/5.png" alt="5"></p></li><li><p>选择安装路径（不要带中文）</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/6.png" alt="6"></p></li><li><p>选择组件，其中：</p><ul><li><p>MSVC：Microsoft Visual C++ Compiler，微软的VC编译器</p></li><li><p>MinGW：Minimalist GNU for Window，将GCC编译器和GNU Binutils移植到Windows平台下的产物，它是一些头文件和使用 GNU 工具集导入库的集合，允许用户在没有第三方 dll 的情况下生成本地的 Windows 程序</p><p><strong><font color="#0000dd">注：</font></strong></p><p><strong><font color="#0000dd">MSVC 和 MingGW 都是很好用的工具，但兼容并不好，比如某项目使用了 MingGW 编译，那么它所链接的库也必须是 MingGW 编译而成。 一般来说，如果仅在 Windows 平台开发，选择 MSVC，可以使用大量的第三方库；如果有跨平台需求，选择 MingGW。</font></strong></p><p><strong><font color="#0000dd">由于两个版本的Qt配置方式完全不同。因此在网上搜配置方法的时候，要加上MSVC或者MinGW这样的关键字搜索。</font></strong></p></li><li><p>UWP：属于 MSVC 编译器生成的 Qt 库，用于开发通用 Windows 平台的应用程序</p></li><li><p>Android：用于 Android 应用开发的 Qt 库</p></li><li><p>Sources：源码包，添加后可以使用源码调试功能</p></li><li><p>Qt Charts：二维图表模块，用于绘制柱状图、饼图、曲线图等常用二维图表</p></li><li><p>Qt Data Visualization：三维数据图表模块，用于数据的三维显示，如散点的三维空间分布、三维曲面等。</p></li></ul><ul><li>Qt Purchasing：用于处理 Android、iOS 和 macOS 上的应用内购买的跨平台 API</li><li>Qt Virtual Keyboard：Qt Quick 虚拟键盘</li><li>Qt WebEngine：集成了Google Chromium Web，充分利用了整个 Qt 图形堆栈集成，允许原生 Qt 控件与 Web 内容和 OpenGL 着色器的无缝混合和叠加</li><li>Qt Network Authorization：Qt 网络授权是一个附加库，它使 Qt 应用程序能够使用不同的 Web 身份验证系统</li><li>Qt WebGL Streaming Plugin：一个 Qt Platform Abstraction 插件，它通过网络将 Qt Quick &amp; Qt OpenGL 应用程序流式传输到支持 WebGL 的浏览器。</li><li><del>Qt Script (Deprecated)：脚本模块，已弃用</del></li></ul><p>Tools 节点下的工具：</p><ul><li><p>Qt Creator：Qt5.0版本以上集成的轻量级跨平台集成开发环境（5.0以下需要单独安装）</p></li><li><p>CDB Debugger Support：控制台调试器，是 MSVC 在 Qt 的原生调试器，由于MSVC 只有编译器，如果选择它，则需要勾选；如选择 MinGW 则不需要，MinGW 中有 GDB调试器</p></li><li><p>MingGW ：这里的 MingGW 是用来交叉编译的，在一个平台上生成另一个平台上的可执行代码</p></li><li><p>Strawberry Perl：Perl 语言工具</p><p>根据个人需要，我选择了以下组件（若不确定选哪个，可以全选）</p></li></ul><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/7.png" alt="7"></p></li><li><p>许可协议</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/8.png" alt="8"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/9.png" alt="9"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/10.png" alt="10"></p></li><li><p>等待安装完成</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/11.png" alt="11"></p></li><li><p>安装完成</p></li></ol><p>   <img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/12.png" alt="12"></p><h2 id="创建快捷方式"><a href="#创建快捷方式" class="headerlink" title="创建快捷方式"></a>创建快捷方式</h2><p>安装好后的Qt Creator未在桌面创建快捷方式，可以使用以下方式创建：</p><ol><li><p>打开“开始菜单”，找到安装好的“Qt Creator”，然后“右键”-&gt;“更多”-&gt;“打开文件位置”</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/13.jpg" alt="13"></p></li><li><p>在“Qt Creator”上右键，然后”发送到”-&gt;“桌面快捷方式”</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/14.jpg" alt="14"></p></li></ol><h2 id="“Hello-World”之第一个Qt应用"><a href="#“Hello-World”之第一个Qt应用" class="headerlink" title="“Hello World”之第一个Qt应用"></a>“Hello World”之第一个Qt应用</h2><ol><li><p>打开Qt Creator，“文件”-&gt;“新建文件或项目”</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/15.png" alt="15"></p></li><li><p>选择模板，部分选项如下：</p><ul><li>Qt Widgets Application，支持桌面平台的GUI 界面应用程序</li><li>Qt Console Application，控制台应用程序，无 GUI 界面</li><li>Application（Qt Quick），创建可部署的 Qt Quick 2 应用程序。Qt Quick 是 Qt 支持的一套 GUI 开发架构，其界面设计采用 QML 语言，程序架构采用 C++ 语言。利用 Qt Quick 可以设计非常炫的用户界面，一般用于移动设备或嵌入式设备上无边框的应用程序的设计</li></ul><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/16.png" alt="16"></p></li><li><p>工程路径，注意路径及工程名字不能含有空格或中文</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/17.png" alt="17"></p></li><li><p>选择构建系统，其中：</p><ul><li>qmake，为 Qt 量身打造的，使用起来非常方便</li><li>cmake，使用上不如qmake简单直接，但复杂换来的是强大的功能</li><li>Qbs ，号称下一代构建工具</li></ul><p>对简单的Qt工程，采用 qmake；对复杂度超过 qmake 处理能力的，采用 cmake。这里我选择qmake。</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/18.png" alt="18"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/19.png" alt="19"></p></li><li><p>翻译文件，用于国际化，暂时不用设置，默认即可</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/20.png" alt="20"></p></li><li><p>选择构建套件，这里我选择MinGW 64-bit，不同构建套件的区别见上面“安装Qt”中的“选择组件”步骤</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/21.png" alt="21"></p></li><li><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/22.png" alt="22"></p></li><li><p>打开 .ui 文件</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/23.png" alt="23"></p></li><li><p>在“Display Widgets”下拖一个“Label”到中间，在其中填入“Hello World”，并在右侧修改宽度</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/24.png" alt="24"></p></li><li><p>点击左下角的“绿色三角形”运行程序</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/25.png" alt="25"></p></li><li><p>程序运行成果，显示GUI界面</p><p><img src="/2023/07/08/Qt%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/26.png" alt="26"></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 开发工具 </category>
          
          <category> Qt </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 入门 </tag>
            
            <tag> C++ </tag>
            
            <tag> Qt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>离思五首·其四</title>
      <link href="/2023/07/08/%E7%A6%BB%E6%80%9D%E4%BA%94%E9%A6%96%C2%B7%E5%85%B6%E5%9B%9B/"/>
      <url>/2023/07/08/%E7%A6%BB%E6%80%9D%E4%BA%94%E9%A6%96%C2%B7%E5%85%B6%E5%9B%9B/</url>
      
        <content type="html"><![CDATA[<center>离思五首·其四</center><p align="right">元稹【唐】</p><hr><center>曾经沧海难为水，</center><center>除却巫山不是云。</center><center>取次花丛懒回顾，</center><center>半缘修道半缘君。</center><p>第一次读到这首诗的时候，因为没读懂“曾经”两个字，所以对前两句半知半解，只觉得后两句写得很妙。后来某一天突然醒悟过来，“曾经”是两个词：曾经经过，这才体会到前两句的韵味。特别是最近想起来这首诗，更是咂摸出一番新的滋味。<br>“领略过沧海的波涛汹涌，别处的水就不值得看了；沉醉过巫山云景的梦幻飘渺，别处的云都不能被叫作云景了；即使从万花丛中走过，也懒得看一眼”如果只读到前三句，可能会是一头雾水，这到底想表达什么意思？为什么别处的水不值得看？为什么别处的云不能被叫作云景？为什么不看一眼身边的花？正当疑问之时，最后一句点名原因“一半是因为我在修道，另一半是因为你呀！”<br>个人认为，这首诗除了前两句的比喻极其绝妙之外，整体结构上也是极具深意的，可以说是含蓄美的极致体现。前三句不明说对你的爱慕，只是说沧海、说巫山云雨、说万花丛，直到最后一句点睛之笔才知道这哪是在说什么沧海云雨，这句句都是在说心上人啊！哪怕到了最后点名原因了，还要再说一句“半缘修道”，可是真的有一半原因是修道吗？恐怕未必，或者说“修道”本身也是“缘君”。这种写法， 层层递进，先是三句描写自己心态的句子，然后自然而然的说出自己为何这样，虽然整体上感觉不到太大的感情波动，但却将思恋之情委婉而又淋漓尽致的表现了出来。<br>如果换成现在，或许就是这样吧：<br>今天的晚霞好美，像一条红绸带从天边垂下；晚饭也很香，炸鸡腿外焦里嫩，咬一口嘎吱响。<br>但是我不想去看晚霞也没心思吃饭。<br>为什么？<br>因为最近很忙很累，嗯，更重要的是，好久不见想你了……</p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
          <category> 诗 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 诗 </tag>
            
            <tag> 唐 </tag>
            
            <tag> 元稹 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
